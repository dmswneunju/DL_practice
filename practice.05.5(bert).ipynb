{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d56d98c",
   "metadata": {},
   "source": [
    "## 5-5. 데이터 전처리 및 Pre-Trained Embedding Vector를 이용한 Vocabulary생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4293df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 23 17:39:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 25%   35C    P0    N/A /  30W |   1924MiB /  2048MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       928    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      1320    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      4992    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5352    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7896    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      8540    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      8696      C   ...\\envs\\practice\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      9344    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11256    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     11892    C+G   ...oft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     12228    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69aa087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from importlib-metadata->transformers) (3.13.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leeej\\anaconda3\\envs\\practice\\lib\\site-packages (from requests->transformers) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1492a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5ff3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a89a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'dog', 'is', 'cute', '.', 'he', 'likes', 'playing', '.', 'i', 'bought', 'a', 'pet', 'food', 'for', 'him']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My dog is cute. He likes playing. I bought a  pet food for him\"\n",
    "# sentence = '나는 책상 위에 사과를 먹었다. 알고 보니 그 사과는 Jason 것이었다. 그래서 Jason에게 사과를 했다'\n",
    "print(tokenizer.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3becf5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feeb27f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "#BERT사용하려면 IMDb데이터를 BERT가 학습됐던 input과 동일하게 맞춰야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d51797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_tokenizer(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc23c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessingText(input_sentence):\n",
    "    input_sentence = input_sentence.lower() # 소문자화\n",
    "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
    "    input_sentence = re.sub('[!\"$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
    "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
    "    if input_sentence:\n",
    "        return input_sentence\n",
    "\n",
    "def PreProc(list_sentence):\n",
    "    return [tokenizer.convert_tokens_to_ids(PreProcessingText(x)) for x in list_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38298994",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = new_tokenizer,\n",
    "                  preprocessing = PreProc,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "LABEL.build_vocab(train_data)\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(0), split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289ec3d",
   "metadata": {},
   "source": [
    "## Reading Data(IMDb data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ef1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Length : 20000\n",
      "Test Data Length : 25000\n"
     ]
    }
   ],
   "source": [
    "# Data Length\n",
    "print(f'Train Data Length : {len(train_data.examples)}') #data.examples : 데이터의 개수 확인\n",
    "print(f'Test Data Length : {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda1dc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x16edb84d448>,\n",
       " 'label': <torchtext.data.field.LabelField at 0x16edb84c988>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Fields\n",
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9510c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Data Sample ----\n",
      "Input : \n",
      "['another', 'in', 'a', 'long', 'line', 'of', 'flick', '##s', 'made', 'by', 'people', 'who', 'think', 'that', 'knowing', 'how', 'to', 'operate', 'a', 'camera', 'is', 'the', 'same', 'as', 'telling', 'a', 'story', '[UNK]', 'within', '15', 'minutes', '[UNK]', 'the', 'entire', 'premise', 'is', 'laid', 'out', 'in', 'just', 'a', 'few', 'lines', '[UNK]', 'so', 'there', 'is', 'absolutely', 'no', 'mystery', '[UNK]', 'which', 'eliminate', '##s', 'a', 'whole', 'face', '##t', 'of', 'the', 'suspense', '[UNK]', 'the', 'only', 'half', '[UNK]', 'way', 'competent', 'actor', 'is', 'killed', '10', 'minutes', 'into', 'the', 'film', '[UNK]', 'so', 'we', \"'\", 're', 'left', 'with', 'stupid', 'characters', 'running', 'around', 'doing', 'stupid', 'things', '[UNK]', 'low', 'budget', 'films', 'can', \"'\", 't', 'afford', 'expensive', 'special', 'effects', '[UNK]', 'so', 'the', 'c', '##gi', 'portions', 'are', 'un', '##sur', '##pr', '##ising', '##ly', 'un', '##im', '##pressive', '[UNK]', 'but', 'were', 'at', 'least', 'a', 'valid', 'attempt', '[UNK]', 'the', 'creature', 'suit', 'is', 'terrible', '[UNK]', 'as', 'seen', 'when', 'it', 'falls', 'to', 'the', 'sidewalk', '[UNK]', 'and', 'the', 'director', 'keeps', 'emphasizing', 'the', 'eyes', '[UNK]', 'which', 'aren', \"'\", 't', 'even', 'the', 'red', 'color', 'shown', 'in', 'mirror', 'shots', '[UNK]', 'the', 'dialogue', 'is', 'clumsy', 'and', 'un', '##ins', '##pired', '[UNK]', 'with', 'some', 'lines', 'reminiscent', 'of', 'aliens', 'or', 'term', '##inator', '[UNK]', 'the', 'last', 'action', 'sequence', 'takes', 'place', 'in', 'a', 'police', 'station', '[UNK]', 'also', 'a', 'rip', '[UNK]', 'off', 'from', 'term', '##inator', '[UNK]', 'with', 'everyone', 'hiding', 'in', 'the', 'one', 'glass', 'lined', 'office', 'that', 'the', 'dark', '##wo', '##lf', 'doesn', \"'\", 't', 'smash', 'into', '[UNK]', 'in', 'the', 'end', '[UNK]', 'the', 'girl', 'calls', 'the', 'hero', '[UNK]', 'a', 'good', 'protector', '[UNK]', '[UNK]', 'but', 'he', 'gets', 'both', 'his', 'partners', '[UNK]', 'the', 'original', 'protector', '[UNK]', 'and', 'at', 'least', 'three', 'other', 'civilians', '[UNK]', 'not', 'to', 'mention', 'a', 'dozen', 'cops', '[UNK]', 'all', 'killed', 'without', 'getting', 'a', 'decent', 'shot', 'off', '[UNK]', 'in', 'spite', 'of', 'an', 'arsenal', 'of', 'silver', 'bullets', 'and', 'a', 'sub', '##mac', '##hine', 'gun', '[UNK]', 'but', 'here', \"'\", 's', 'the', 'real', 'clinch', '##er', 'for', 'bad', 'writing', '[UNK]', 'they', 'could', 'have', 'killed', 'the', 'beast', 'right', 'after', 'the', 'beginning', 'credits', 'when', 'it', 'was', 'holding', 'the', 'strip', '##per', 'while', 'flashing', 'its', 'red', 'eyes', '[UNK]', 'instead', '[UNK]', 'they', 'took', 'it', 'into', 'custody', '[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "# Data Sample\n",
    "print('---- Data Sample ----')\n",
    "print('Input : ')\n",
    "print(tokenizer.convert_ids_to_tokens(vars(train_data.examples[2])['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e91b5",
   "metadata": {},
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425d7f7",
   "metadata": {},
   "source": [
    "## making vocab & setting embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93501dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Size : 2\n",
      "Lable Examples : \n",
      "\t neg 0\n",
      "\t pos 1\n"
     ]
    }
   ],
   "source": [
    "# Label Info\n",
    "print(f'Label Size : {len(LABEL.vocab)}')\n",
    "\n",
    "print('Lable Examples : ')\n",
    "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
    "    print('\\t', k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b6a7a",
   "metadata": {},
   "source": [
    "## spliting validation data & making data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfb12e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {}\n",
    "\n",
    "model_config['batch_size'] = 8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=model_config['batch_size'],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a163294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 8]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 8x512 (GPU 0)]\n",
      "\t[.label]:[torch.cuda.FloatTensor of size 8 (GPU 0)]\n",
      "tensor([[ 101, 5752, 7104,  ...,    0,    0,    0],\n",
      "        [ 101,  100, 8334,  ...,    0,    0,    0],\n",
      "        [ 101, 1053,  100,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1996, 2143,  ...,    0,    0,    0],\n",
      "        [ 101, 4931, 2065,  ...,    0,    0,    0],\n",
      "        [ 101, 2023, 3185,  ...,    0,    0,    0]], device='cuda:0')\n",
      "tensor([1., 1., 1., 0., 0., 0., 0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check batch data\n",
    "sample_for_check = next(iter(train_iterator))\n",
    "print(sample_for_check)\n",
    "print(sample_for_check.text)\n",
    "print(sample_for_check.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982fa3e",
   "metadata": {},
   "source": [
    "## Pytorch에서 RNN, LSTM, GRU을 이용한 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ce9b6",
   "metadata": {},
   "source": [
    "## Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a391d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "register_buffer() got an unexpected keyword argument 'persistent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2664\\3520400581.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emb_dim'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hidden_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'emb_dim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\practice\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m         \u001b[1;31m# Check first if we are `from_pt`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\practice\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\practice\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"position_ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_position_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         self.register_buffer(\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         )\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: register_buffer() got an unexpected keyword argument 'persistent'"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model_config['emb_dim'] = bert.config.to_dict()['hidden_size']\n",
    "\n",
    "print(model_config['emb_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86799e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassification(nn.Module):\n",
    "    def __init__(self, **model_config):\n",
    "        super(SentenceClassification, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.fc = nn.Linear(model_config['emb_dim'],\n",
    "                            model_config['output_dim'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pooled_cls_output = self.bert(x)[1]\n",
    "        return self.fc(pooled_cls_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4b60e",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e0196a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train() \n",
    "    batch_size = model_params['batch_size']\n",
    "\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        # Initializing\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward \n",
    "        predictions = model(batch.text).squeeze()\n",
    "        loss = loss_fn(predictions, batch.label)\n",
    "\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "\n",
    "        # Backward \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Epoch Performance\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "304c16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_fn, idx_epoch, **model_params):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    batch_size = model_params['batch_size']\n",
    "    \n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(iterator):\n",
    "            predictions = model(batch.text).squeeze()\n",
    "            loss = loss_fn(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            sys.stdout.write(\n",
    "                    \"\\r\" + f\"[Eval] Epoch : {idx_epoch:^3}\"\\\n",
    "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
    "                    f\"  Loss: {loss.item():.4}\"\\\n",
    "                    f\"  Acc : {acc.item():.4}\"\\\n",
    "                    )\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31c63b",
   "metadata": {},
   "source": [
    "## bi-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5400e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.update(dict(output_dim = 1))\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    # rounded_preds = torch.argmax(preds, axis=1) \n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "model = SentenceClassification(**model_config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30076b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Model name : bi-RNN_\n",
      "---------------------------------\n",
      "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.6795  Acc : 0.5333\n",
      "\t Saved at 0-epoch\n",
      "\t Epoch : 0 | Train Loss : 0.6333 | Train Acc : 0.6351\n",
      "\t Epoch : 0 | Valid Loss : 0.6239 | Valid Acc : 0.6356\n",
      "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.7517  Acc : 0.6333\n",
      "\t Epoch : 1 | Train Loss : 0.6192 | Train Acc : 0.6449\n",
      "\t Epoch : 1 | Valid Loss : 0.6446 | Valid Acc : 0.6201\n",
      "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.6333  Acc : 0.7333\n",
      "\t Epoch : 2 | Train Loss : 0.6027 | Train Acc : 0.6623\n",
      "\t Epoch : 2 | Valid Loss : 0.6562 | Valid Acc : 0.6108\n",
      "[Train] Epoch :  3 [14940 / 20010 (74.66%)]  Loss: 0.6388  Acc : 0.7677"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 4\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = \"BERT\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    print('')\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn, epoch, **model_config)\n",
    "    print('')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')\n",
    "    # print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Model is saved at {epoch}-epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "# model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "epoch = 0\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn, epoch, **model_config)\n",
    "print('')\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "epoch = 0\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn, epoch, **model_config)\n",
    "print('')\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b351f0",
   "metadata": {},
   "source": [
    "## bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'LSTM'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8eca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e90beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a7f87",
   "metadata": {},
   "source": [
    "## bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4443678",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCH = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
    "\n",
    "print('---------------------------------')\n",
    "print(f'Model name : {model_name}')\n",
    "print('---------------------------------')\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
    "    print('')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
    "        print(f'\\t Saved at {epoch}-epoch')\n",
    "\n",
    "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
    "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe453ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
    "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96535f",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ff24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['model_type'] = 'GRU'\n",
    "model = SentenceClassification(**model_config).to(device)\n",
    "model.load_state_dict(torch.load(f\"./{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14515ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    indexed = TEXT.numericalize(TEXT.pad([TEXT.tokenize(PreProcessingText(sentence))]))\n",
    "    input_data = torch.LongTensor(indexed).to(device)\n",
    "    prediction = torch.sigmoid(model(input_data))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = 'this movie is FUN'\n",
    "predict_sentiment(model = model, sentence = test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb264a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e6c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab56b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ef293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac289b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice[py-3.7]",
   "language": "python",
   "name": "practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
